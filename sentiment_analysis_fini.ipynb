{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "21b92757c2eebd12",
      "metadata": {
        "collapsed": false,
        "id": "21b92757c2eebd12"
      },
      "source": [
        "# Welcome !\n",
        "\n",
        "> Let's see what we can do together. Let's take a look at some sentiment analysis.\n",
        "\n",
        "***To detect good sentences from bad we will use some TF-IDF matrices: Term-frequency - Inverse-Document-Frequency***\n",
        "\n",
        "\n",
        "### What is it?\n",
        "Let's say we have for example: **\"I love this cat\"** and **\"I love this dog\"**, **\"I hate the movie\"**\n",
        "In this case, we can see that the frequency of love over the first sentence is 1, over the second 1 and finally 0.\n",
        "The global frequency is 2.\n",
        "Let's take a look at: \"I\", the frequency over all sentences is respectively 1.\n",
        "The global fequency of I over the document (3 sentences) is 3.\n",
        "\n",
        "### Does it mean \"I\" is more important than \"love\"?\n",
        "Nop, you're right, \"I\" is not more important. To focus on correctness of the frequency over all documents, we have to multiply the TF (term fequency) with the IDF (inverse-document-frequency):\n",
        "\n",
        "***TF * log(N/df)***\n",
        "\n",
        "N = 3 (because 3 sentences)\n",
        "* For \"I\":\n",
        "TF = 1 for the first sentence\n",
        "df = 3 because \"I\" appears in all 3 documents\n",
        "\n",
        "**TF-IDF(\"I\") = 0**, therefore, \"I\" in the first document is not a valuable information.\n",
        "\n",
        "* For \"love\":\n",
        "TF = 1 for the first sentence\n",
        "df = 2 because \"love\" appears in 2 / 3 documents\n",
        "\n",
        "**TF-IDF(\"love\")** = 0.17, therefore \"love\" is a little valuable in the first sentence.\n",
        "\n",
        "***PS: this approach will be quite wrong as it will not take into account any context.***\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cff87a02659db489",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-16T23:53:28.780998900Z",
          "start_time": "2023-11-16T23:53:28.652737700Z"
        },
        "id": "cff87a02659db489"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e79f277a036e4490",
      "metadata": {
        "collapsed": false,
        "id": "e79f277a036e4490"
      },
      "source": [
        "### Below is some bad and good\n",
        "\n",
        "We will use those sentences to create two TF-IDF matrices: one good, one bad.\n",
        "Later, we will compare every sentence we want with the two matrices and check which of the two has the closest cosine similarity (distance) in terms of TF-IDF value with the sentence we want to predict the sentiment.\n",
        "If you don't understand yet, no worries keep up!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e7ae5c7ae41f599d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-16T23:53:28.782993500Z",
          "start_time": "2023-11-16T23:53:28.681749200Z"
        },
        "id": "e7ae5c7ae41f599d"
      },
      "outputs": [],
      "source": [
        "bad_sentences = [\n",
        "    ['I', 'hate', 'this'],\n",
        "    ['I', 'don\\'t', 'like', 'it'],\n",
        "    ['I', 'hate', 'that'],\n",
        "    ['What', 'a', 'disaster'],\n",
        "    ['Not', 'good'],\n",
        "    ['It', 'is', 'bad'],\n",
        "    ['I', 'am', 'not', 'happy'],\n",
        "    ['I', 'am', 'unhappy'],\n",
        "    ['I', 'am', 'sad'],\n",
        "    ['I', 'am', 'mad'],\n",
        "    ['I', 'am', 'angry'],\n",
        "    ['I', 'am', 'not', 'glad'],\n",
        "    ['I', 'am', 'not', 'pleased'],\n",
        "    ['I', 'am', 'not', 'satisfied'],\n",
        "    ['I', 'am', 'not', 'content'],\n",
        "    ['I', 'am', 'not', 'cheerful'],\n",
        "    ['I', 'am', 'not', 'delighted'],\n",
        "    ['I', 'am', 'not', 'joyful'],\n",
        "    ['I', 'am', 'not', 'joyous'],\n",
        "    ['I', 'am', 'not', 'jubilant'],\n",
        "    ['I', 'am', 'not', 'ecstatic'],\n",
        "    ['I', 'am', 'not', 'elated'],\n",
        "    ['I', 'am', 'not', 'overjoyed'],\n",
        "    ['I', 'am', 'not', 'thrilled'],\n",
        "    ['I', 'am', 'not', 'excited'],\n",
        "    ['I', 'am', 'not', 'exhilarated'],\n",
        "    ['I', 'am', 'not', 'euphoric'],\n",
        "    ['I', 'am', 'not', 'blissful'],\n",
        "    ['I', 'am', 'not', 'cheery'],\n",
        "    ['I', 'am', 'not', 'chipper'],\n",
        "    ['I', 'am', 'not', 'contented'],\n",
        "    ['I', 'am', 'not', 'enjoying'],\n",
        "    ['I', 'am', 'not', 'glad'],\n",
        "    ['I', 'am', 'not', 'gratified'],\n",
        "    ['I', 'am', 'not', 'gratifying'],\n",
        "    ['I', 'am', 'not', 'happy'],\n",
        "    ['I', 'am', 'not', 'joyous'],\n",
        "    ['I', 'am', 'not', 'jubilant'],\n",
        "    ['I', 'am', 'not', 'pleased'],\n",
        "    ['I', 'am', 'not', 'pleasing'],\n",
        "    ['I', 'am', 'not', 'satisfied']\n",
        "]\n",
        "\n",
        "good_sentences = [\n",
        "    ['I', 'love', 'this'],\n",
        "    ['I', 'like', 'it'],\n",
        "    ['I', 'love', 'it'],\n",
        "    ['What', 'a', 'wonderful', 'day'],\n",
        "    ['Good'],\n",
        "    ['It', 'is', 'good'],\n",
        "    ['I', 'am', 'happy'],\n",
        "    ['I', 'am', 'glad'],\n",
        "    ['I', 'am', 'pleased'],\n",
        "    ['I', 'am', 'satisfied'],\n",
        "    ['I', 'am', 'content'],\n",
        "    ['I', 'am', 'cheerful'],\n",
        "    ['I', 'am', 'delighted'],\n",
        "    ['I', 'am', 'joyful'],\n",
        "    ['I', 'am', 'joyous'],\n",
        "    ['I', 'am', 'jubilant'],\n",
        "    ['I', 'am', 'ecstatic'],\n",
        "    ['I', 'am', 'elated'],\n",
        "    ['I', 'am', 'overjoyed'],\n",
        "    ['I', 'am', 'thrilled'],\n",
        "    ['I', 'am', 'excited'],\n",
        "    ['I', 'am', 'exhilarated'],\n",
        "    ['I', 'love', 'that', 'a', 'lot'],\n",
        "    ['I', 'am', 'euphoric'],\n",
        "    ['I', 'am', 'pleased'],\n",
        "    ['I', 'am', 'pleasing'],\n",
        "    ['I', 'am', 'satisfied']\n",
        "\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b0b3d075f0e1aa3",
      "metadata": {
        "collapsed": false,
        "id": "5b0b3d075f0e1aa3"
      },
      "source": [
        "### 1. Term Frequency\n",
        "As we said earlier, we will first calculate the term frequency of each word in each sentence.\n",
        "\n",
        "->TIPS:\n",
        "- Create an empty dictionary\n",
        "- Loop over each sentence\n",
        "- Loop over each word in the sentence\n",
        "- If the word is already in the dictionary, add 1 to the value\n",
        "- If the word is not in the dictionary, add the word as a key and set the value to 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "initial_id",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-16T23:53:28.782993500Z",
          "start_time": "2023-11-16T23:53:28.692721900Z"
        },
        "collapsed": true,
        "id": "initial_id"
      },
      "outputs": [],
      "source": [
        "from os import X_OK\n",
        "def term_frequency(tokenized_sentences):\n",
        "    d = {}\n",
        "    x = 1\n",
        "\n",
        "    for phrase in tokenized_sentences :\n",
        "      for mot in phrase :\n",
        "        if mot in d :\n",
        "          d[mot] +=1\n",
        "        else :\n",
        "          d[mot] = 1\n",
        "\n",
        "    return d\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "67c6b8b87cb1faa9",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-16T23:53:28.782993500Z",
          "start_time": "2023-11-16T23:53:28.708679100Z"
        },
        "id": "67c6b8b87cb1faa9"
      },
      "outputs": [],
      "source": [
        "tf_bad = term_frequency(bad_sentences)\n",
        "tf_good = term_frequency(good_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "59dcd882e2387d7d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-16T23:53:28.783990800Z",
          "start_time": "2023-11-16T23:53:28.722640Z"
        },
        "id": "59dcd882e2387d7d"
      },
      "outputs": [],
      "source": [
        "global_shape = len(tf_bad) + len(tf_good)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cf83f88f6493b8b",
      "metadata": {
        "collapsed": false,
        "id": "7cf83f88f6493b8b"
      },
      "source": [
        "### 2. TF Matrix\n",
        "Now that we have the term frequency of each word, we will create a matrix with the shape of the number of sentences and the number of words in the dictionary.\n",
        "\n",
        "->TIPS:\n",
        "- Create an empty matrix (list of lists)\n",
        "- Loop over each sentence\n",
        "- Create an empty vector (list) of the size: global_shape (this is because we are going to create two TF-IDF matrices: one for good sentences and one for bad sentences. The global_shape will be the same for both matrices)\n",
        "- Loop over each word in the sentence\n",
        "- If the word is in the dictionary, add the number of times the word appears in the sentence to the vector\n",
        "- If the word is not in the dictionary, add 0 to the vector\n",
        "- Add the vector to the matrix\n",
        "- Return the matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b472ad32c366de3e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-16T23:53:28.783990800Z",
          "start_time": "2023-11-16T23:53:28.739619Z"
        },
        "id": "b472ad32c366de3e"
      },
      "outputs": [],
      "source": [
        "def tf_matrix(tokenized_sentences, tf):\n",
        "    matrice = []\n",
        "    for phrase in tokenized_sentences :\n",
        "      v = [0]* global_shape\n",
        "      for mot in phrase :\n",
        "        if mot in tf :\n",
        "          val = list(tf.keys()).index(mot)\n",
        "          nb_mot = phrase.count(mot)\n",
        "          v[val]=nb_mot\n",
        "\n",
        "        else :\n",
        "          v.append(0)\n",
        "      matrice.append(v)\n",
        "    return matrice\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "756b6ccfe6c8b416",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-16T23:53:28.783990800Z",
          "start_time": "2023-11-16T23:53:28.754557400Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "756b6ccfe6c8b416",
        "outputId": "e2526700-3c42-4a1a-d163-42f6ab419343"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
          ]
        }
      ],
      "source": [
        "tf_matrix_bad = tf_matrix(bad_sentences, tf_bad)\n",
        "tf_matrix_good = tf_matrix(good_sentences, tf_good)\n",
        "print(tf_matrix_bad)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b0cc8c3af14cd5e",
      "metadata": {
        "collapsed": false,
        "id": "7b0cc8c3af14cd5e"
      },
      "source": [
        "### 3. IDF Matrix\n",
        "Now that we have the TF matrix, we will create the IDF matrix.\n",
        "\n",
        "->TIPS:\n",
        "- Create an empty vector (list)\n",
        "- Loop over each rows (sentences) of the tf_matrix\n",
        "- Create a counter\n",
        "- Loop over each sentence\n",
        "- If the word is in the sentence, add 1 to the counter\n",
        "- Add the log of the number of sentences divided by the counter + 1 to the vector\n",
        "- Return the vector\n",
        "\n",
        "->TIPS:\n",
        "- Create an empty vector (list)\n",
        "- Loop over each rows (sentences) of the tf_matrix\n",
        "- Create a counter\n",
        "- Loop over each columns(words) of the tf_matrix\n",
        "- If the word is in the sentence, add 1 to the counter\n",
        "- Add the log of the number of sentences divided by the counter + 1 to the vector\n",
        "- Return the vector\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "d5e79992cc89abad",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-16T23:53:28.812969200Z",
          "start_time": "2023-11-16T23:53:28.769031500Z"
        },
        "id": "d5e79992cc89abad"
      },
      "outputs": [],
      "source": [
        "def idf_matrix(tf_matrix):\n",
        "    IDF = []\n",
        "    for phrase in range(len(tf_matrix[0])):\n",
        "      nb_phrase = 0\n",
        "      for mot in range(len(tf_matrix)):\n",
        "        if tf_matrix[mot][phrase] != 0:\n",
        "          nb_phrase += 1\n",
        "      IDF.append(np.log((len(tf_matrix))/(nb_phrase + 1)))\n",
        "\n",
        "    print(\"Taille de la matrice IDF : \\n\", np.array(IDF).shape)\n",
        "    print(\"Matrice IDF : \\n\", np.array(IDF))\n",
        "    return IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "1e544edc28877019",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-16T23:53:28.813910700Z",
          "start_time": "2023-11-16T23:53:28.785985700Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e544edc28877019",
        "outputId": "9ef2f510-9c00-465c-9cfa-a0075b30802c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Taille de la matrice IDF : \n",
            " (80,)\n",
            "Matrice IDF : \n",
            " [0.05001042 2.61495978 3.02042489 3.02042489 3.02042489 3.02042489\n",
            " 3.02042489 3.02042489 3.02042489 3.02042489 3.02042489 3.02042489\n",
            " 3.02042489 3.02042489 3.02042489 0.13005313 0.24783616 2.61495978\n",
            " 3.02042489 3.02042489 3.02042489 3.02042489 2.61495978 2.61495978\n",
            " 2.61495978 3.02042489 3.02042489 3.02042489 3.02042489 2.61495978\n",
            " 2.61495978 3.02042489 3.02042489 3.02042489 3.02042489 3.02042489\n",
            " 3.02042489 3.02042489 3.02042489 3.02042489 3.02042489 3.02042489\n",
            " 3.02042489 3.02042489 3.02042489 3.02042489 3.71357207 3.71357207\n",
            " 3.71357207 3.71357207 3.71357207 3.71357207 3.71357207 3.71357207\n",
            " 3.71357207 3.71357207 3.71357207 3.71357207 3.71357207 3.71357207\n",
            " 3.71357207 3.71357207 3.71357207 3.71357207 3.71357207 3.71357207\n",
            " 3.71357207 3.71357207 3.71357207 3.71357207 3.71357207 3.71357207\n",
            " 3.71357207 3.71357207 3.71357207 3.71357207 3.71357207 3.71357207\n",
            " 3.71357207 3.71357207]\n",
            "Taille de la matrice IDF : \n",
            " (80,)\n",
            "Matrice IDF : \n",
            " [0.07696104 1.9095425  2.60268969 2.60268969 2.19722458 2.60268969\n",
            " 2.19722458 2.60268969 2.60268969 2.60268969 2.60268969 2.60268969\n",
            " 2.60268969 0.25131443 2.60268969 2.60268969 2.19722458 2.19722458\n",
            " 2.60268969 2.60268969 2.60268969 2.60268969 2.60268969 2.60268969\n",
            " 2.60268969 2.60268969 2.60268969 2.60268969 2.60268969 2.60268969\n",
            " 2.60268969 2.60268969 2.60268969 2.60268969 3.29583687 3.29583687\n",
            " 3.29583687 3.29583687 3.29583687 3.29583687 3.29583687 3.29583687\n",
            " 3.29583687 3.29583687 3.29583687 3.29583687 3.29583687 3.29583687\n",
            " 3.29583687 3.29583687 3.29583687 3.29583687 3.29583687 3.29583687\n",
            " 3.29583687 3.29583687 3.29583687 3.29583687 3.29583687 3.29583687\n",
            " 3.29583687 3.29583687 3.29583687 3.29583687 3.29583687 3.29583687\n",
            " 3.29583687 3.29583687 3.29583687 3.29583687 3.29583687 3.29583687\n",
            " 3.29583687 3.29583687 3.29583687 3.29583687 3.29583687 3.29583687\n",
            " 3.29583687 3.29583687]\n"
          ]
        }
      ],
      "source": [
        "idf_matrix_bad = idf_matrix(tf_matrix_bad)\n",
        "idf_matrix_good = idf_matrix(tf_matrix_good)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eefe364a0cb51ad6",
      "metadata": {
        "collapsed": false,
        "id": "eefe364a0cb51ad6"
      },
      "source": [
        "### 4. TF-IDF Matrix\n",
        "Now that we have the TF matrix and the IDF matrix, we will create the TF-IDF matrix.\n",
        "\n",
        "->TIPS:\n",
        "- Create an empty matrix (list of lists)\n",
        "- Loop over the TF matrix\n",
        "- Create an empty vector (list) of the size: global_shape (this is because we are going to create two TF-IDF matrices: one for good sentences and one for bad sentences. The global_shape will be the same for both matrices)\n",
        "- Loop over each word in the sentence\n",
        "- Multiply the TF value with the IDF value\n",
        "- Add the value to the vector\n",
        "- Add the vector to the matrix\n",
        "- Return the matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "9e3e70da8336d719",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-16T23:53:28.890242300Z",
          "start_time": "2023-11-16T23:53:28.804936500Z"
        },
        "id": "9e3e70da8336d719"
      },
      "outputs": [],
      "source": [
        "def tf_idf_matrix(tf_matrix, idf_matrix):\n",
        "  matrice = []\n",
        "  for i in range(len(tf_matrix)) :\n",
        "    vect = []\n",
        "    for mot in range(len(tf_matrix[0])):\n",
        "      vect.append(tf_matrix[i][mot] * idf_matrix[mot])\n",
        "    matrice.append(vect)\n",
        "  print(\"Taille de la matrice TF-IDF : \\n\", np.array(matrice).shape)\n",
        "  print(\"Matrice TF-IDF : \\n\", np.array(matrice))\n",
        "  return matrice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "5dc20545fa263033",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-16T23:53:28.909173400Z",
          "start_time": "2023-11-16T23:53:28.816904100Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dc20545fa263033",
        "outputId": "d1fa959a-2356-4180-8410-7cd1a0f54c60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Taille de la matrice TF-IDF : \n",
            " (41, 80)\n",
            "Matrice TF-IDF : \n",
            " [[0.05001042 2.61495978 3.02042489 ... 0.         0.         0.        ]\n",
            " [0.05001042 0.         0.         ... 0.         0.         0.        ]\n",
            " [0.05001042 2.61495978 0.         ... 0.         0.         0.        ]\n",
            " ...\n",
            " [0.05001042 0.         0.         ... 0.         0.         0.        ]\n",
            " [0.05001042 0.         0.         ... 0.         0.         0.        ]\n",
            " [0.05001042 0.         0.         ... 0.         0.         0.        ]]\n",
            "Taille de la matrice TF-IDF : \n",
            " (27, 80)\n",
            "Matrice TF-IDF : \n",
            " [[0.07696104 1.9095425  2.60268969 ... 0.         0.         0.        ]\n",
            " [0.07696104 0.         0.         ... 0.         0.         0.        ]\n",
            " [0.07696104 1.9095425  0.         ... 0.         0.         0.        ]\n",
            " ...\n",
            " [0.07696104 0.         0.         ... 0.         0.         0.        ]\n",
            " [0.07696104 0.         0.         ... 0.         0.         0.        ]\n",
            " [0.07696104 0.         0.         ... 0.         0.         0.        ]]\n"
          ]
        }
      ],
      "source": [
        "tf_idf_matrix_bad = tf_idf_matrix(tf_matrix_bad, idf_matrix_bad)\n",
        "tf_idf_matrix_good = tf_idf_matrix(tf_matrix_good, idf_matrix_good)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d8b4231f26b3c9a",
      "metadata": {
        "collapsed": false,
        "id": "4d8b4231f26b3c9a"
      },
      "source": [
        "### 5. Check sentiment\n",
        "Now that we have the two TF-IDF matrices, we can check the sentiment of any sentence we want.\n",
        "To check the sentiment, we will calculate the cosine similarity between the sentence we want to check and the two TF-IDF matrices.\n",
        "The TF-IDF matrix with the highest cosine similarity will be the one with the closest distance to the sentence we want to check.\n",
        "\n",
        "For example, for the sentence \"I love this cat\", the cosine similarity with the good TF-IDF matrix could be 0.5 and the cosine similarity with the bad TF-IDF matrix could be 0.2.\n",
        "In this case, the sentence \"I love this cat\" will be considered as a good sentence.\n",
        "\n",
        "->TIPS:\n",
        "- Create a function that takes a query as an input (a sentence)\n",
        "- Create an empty vector (list) of the size: global_shape (this is because we are going to create two TF-IDF matrices: one for good sentences and one for bad sentences. The global_shape will be the same for both matrices)\n",
        "- Combine all words from both tf_bad and tf_good as a set: **all_words = set(list(tf_bad.keys()) + list(tf_good.keys()))**\n",
        "- Loop over each word in the set\n",
        "- If the word is in the query:\n",
        "    - If the word is in tf_bad:\n",
        "        - Add the TF-IDF value to the vector with the index of the word in tf_bad as index and the idf_matrix_bad value as value\n",
        "    - If the word is in tf_good:\n",
        "        - Add the TF-IDF value to the vector with the index of the word in tf_good as index and the idf_matrix_good value as value\n",
        "- Calculate the cosine similarity between the query vector and the good TF-IDF matrix: **cosine_similarity([query_vector], tf_idf_matrix_good)[0][0]**\n",
        "- Calculate the cosine similarity between the query vector and the bad TF-IDF matrix: **cosine_similarity([query_vector], tf_idf_matrix_bad)[0][0]**\n",
        "- If the cosine similarity with the good TF-IDF matrix is higher than the cosine similarity with the bad TF-IDF matrix:\n",
        "    - Print the query with a smiley (or whatever :p)\n",
        "    - Else: print the query with a sad smiley (or whatever :p)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "9873361a3cc40964",
      "metadata": {
        "id": "9873361a3cc40964"
      },
      "outputs": [],
      "source": [
        "good_query = \"WOW, I am so happy to meet you!\"\n",
        "bad_query = \"I hate it a lot\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "c1821720c45a30ed",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-16T23:53:28.910170800Z",
          "start_time": "2023-11-16T23:53:28.846823100Z"
        },
        "id": "c1821720c45a30ed"
      },
      "outputs": [],
      "source": [
        "def check_sentiment(query):\n",
        "  query_mat = query.split()\n",
        "  vect = [0] * global_shape\n",
        "  all_words = set(list(tf_bad.keys()) + list(tf_good.keys()))\n",
        "  for mot in all_words :\n",
        "    if mot in query_mat :\n",
        "      if mot in tf_bad :\n",
        "        ind = list(tf_bad.keys()).index(mot)\n",
        "        val = query_mat.count(mot)* idf_matrix_bad[ind]\n",
        "        vect[ind]=val\n",
        "\n",
        "      elif mot in tf_good :\n",
        "        ind = list(tf_good.keys()).index(mot)\n",
        "        val = query_mat.count(mot)*idf_matrix_good[ind]\n",
        "        vect[ind]=val\n",
        "  coss_good = cosine_similarity([vect], tf_idf_matrix_good)[0][0]\n",
        "  coss_bad = cosine_similarity([vect], tf_idf_matrix_bad)[0][0]\n",
        "\n",
        "\n",
        "  if coss_good >= coss_bad :\n",
        "    print(query, \":)\")\n",
        "  else :\n",
        "    print(query,\":'(\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "3574933f09b890da",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-11-16T23:53:28.910170800Z",
          "start_time": "2023-11-16T23:53:28.860787900Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3574933f09b890da",
        "outputId": "032634c9-7f88-4649-ca2f-968ef7025083"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WOW, I am so happy to meet you! :)\n",
            "I hate it a lot :'(\n"
          ]
        }
      ],
      "source": [
        "check_sentiment(good_query)\n",
        "check_sentiment(bad_query)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
